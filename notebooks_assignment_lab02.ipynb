{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Machine Learning LAB 2: SUPPORT VECTOR MACHINES\n\nCourse 2023/24: *M. Caligiuri*, *P. Talli*, *F. Lincetto*, *F. Chiariotti*, *P. Zanuttigh*\n\nThe notebook contains some simple tasks to be performed with **SUPPORT VECTOR MACHINES (SVM)**.\n\nComplete all the **required code sections** and **answer to all the questions**.\n\n### IMPORTANT for the evaluation score:\n\n1. **Read carefully all cells** and **follow the instructions**.\n2. **Re-run all the code from the beginning** to obtain the results for the final version of your notebook, since this is the way we will do it before evaluating your notebooks.\n3. Make sure to fill the code in the appropriate places **without modifying the template**, otherwise you risk breaking later cells.\n4. Please **submit the jupyter notebook file (.ipynb)**, do not submit python scripts (.py) or plain text files. **Make sure that it runs fine with the restat&run all command**.\n5. **Answer the questions in the appropriate cells**, not in the ones where the question is presented.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Weather Classification with Support Vector Machines\n\nIn this notebook we are going to explore the use of Support Vector Machines (SVM) for weather classification. We will use a dataset collected using the Luxottica **iSee** glasses. These devices provide multiple **sensors mounted inside the glasses**, which can be accessed through a bluetooth connection.\n\n![I-SEE Glasses](data/isee.png \"I-SEE\")\n\nThe dataset corresponds to 8 hours of atmospherical data recordings sampled every 3 seconds.\n\nThe dataset labels are the following:\n\n| ID  | Label       |\n| :-: | :-:         |\n| 0   | Sunny       |\n| 1   | Rain        |\n| 2   | Cloudy      |\n| 3   | Mostly Clear|\n\n---",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Preliminary step\n\nPlace your **name** and **ID number** (matricola) in the cell below. <br>\nAlso recall to **save the file as Surname_Name_LAB02.ipynb**, failure to do so will incur in a **lower grade**.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Student name**: Arman Singh Bains\n\n**ID Number**: 2122166",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Import all the necessary Python libraries",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%matplotlib inline\n\nimport typing as tp\nimport numpy as np\nimport itertools\nfrom matplotlib import pyplot as plt\nimport sklearn.metrics as skm\nfrom sklearn.svm import SVC\nfrom sklearn import linear_model",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "ename": "<class 'ImportError'>",
          "evalue": "dynamic module does not define module export function (PyInit__path)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2454\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2456\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/IPython/core/magics/pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m backends_list)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3630\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menable_matplotlib\u001b[39m(\u001b[38;5;28mself\u001b[39m, gui\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   3610\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Enable interactive matplotlib and inline figure support.\u001b[39;00m\n\u001b[1;32m   3611\u001b[0m \n\u001b[1;32m   3612\u001b[0m \u001b[38;5;124;03m    This takes the following steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[38;5;124;03m        display figures inline.\u001b[39;00m\n\u001b[1;32m   3629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3630\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib_inline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_inline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_inline_support\n\u001b[1;32m   3632\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[1;32m   3633\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mfind_gui_and_backend(gui, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select)\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/matplotlib_inline/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_inline, config  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.6\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/matplotlib_inline/backend_inline.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"A matplotlib backend for publishing figures via display_data\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) IPython Development Team.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Distributed under the terms of the BSD 3-Clause License.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colors\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_agg\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/matplotlib/__init__.py:109\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, docstring, rcsetup\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning, sanitize_sequence\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mplDeprecation  \u001b[38;5;66;03m# deprecated\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/matplotlib/rcsetup.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/matplotlib/colors.py:56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, scale\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/matplotlib/scale.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, docstring\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[1;32m     25\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[1;32m     26\u001b[0m     SymmetricalLogLocator, LogitLocator)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/matplotlib/ticker.py:136\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[1;32m    138\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    140\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    141\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    142\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    149\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/matplotlib/transforms.py:46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m     50\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[0;31mImportError\u001b[0m: dynamic module does not define module export function (PyInit__path)"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Define the heplper functions\n\nIn this section you will find some helper functions (some already implemented, some to be implemented by you) that will be used in the following sections.\n1. `load_dataset` -> to load the dataset from the file `data/lux.npz`,\n2. `plot_input` -> to plot the input data,\n3. `k_split` ->  to split the trainig dataset in k different folds,\n4. `k_fold_cross_validation` -> to perform the k-fold cross validation.\n\n**DO NOT CHANGE THE PRE-WRITTEN CODE UNLESS OTHERWISE SPECIFIED**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Helper function to load the dataset\ndef load_dataset(path: str) -> tp.Tuple[np.ndarray, np.ndarray]:\n    with np.load(path) as data:\n        x, y = data[\"x\"], data[\"y\"]\n        \n        # Normalize the data\n        x -= x.mean(axis=0)\n        x /= x.std(axis=0)\n        \n    return x, y",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Function for plotting a image and printing the corresponding label\ndef plot_input(X_matrix: np.ndarray, labels: np.ndarray) -> None:\n    fig = plt.figure()\n    ax = fig.add_subplot(projection=\"3d\")\n    cmap = plt.cm.get_cmap('Accent', 4)\n    im = ax.scatter(X_matrix[:,0], X_matrix[:,1], X_matrix[:,2], c=labels, cmap=cmap)\n    im.set_clim(-0.5, 3.5)\n    cbar=fig.colorbar(im, ticks=[0,1,2,3], orientation='vertical', cmap=cmap)\n    cbar.ax.set_yticklabels(['Sunny', 'Rainy','Cloudy', 'Mostly clear']) ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Function to split the dataset in k different folds\ndef k_split(x: np.ndarray, y:np.ndarray, k: int, shuffle: bool = True) -> tp.Tuple[list[np.ndarray], list[np.ndarray]]:\n    # Shuffle the dataset\n    if shuffle:\n        # Create a list of indices\n        idx = np.arange(x.shape[0])\n        # Randomly shuffle the indices\n        np.random.shuffle(idx)\n        # Shuffle the dataset\n        x = x[idx]\n        y = y[idx]\n\n    # Split the dataset in k folds\n    # ADD YOUR CODE HERE\n    return (np.split(x, k), np.split(y, k)) # nc",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Function to perform the k-fold cross validation\ndef k_fold_cross_validation(x_train: np.ndarray, y_train: np.ndarray, k: int, model: SVC, parameters: dict) -> tp.Tuple[tuple, tuple]:\n    # Define the folds for the cross validation\n    x_folds, y_folds = k_split(x_train, y_train, k)\n\n    # Build a list containing all of the possible combinatioon of parameters\n    params = list(itertools.product(*parameters.values()))\n\n    # Initialize the dictionary of results\n    results = {k: 0 for k in params}\n\n    # For each param combination, perform the SVM training and testing\n    for param in params:\n        param = dict(zip(parameters.keys(), param))\n\n        fold_accuracies = []\n        \n        # ADD YOUR CODE HERE\n\n        # Compute the mean accuracy\n        results[tuple(param.values())] = round(np.mean(fold_accuracies), 4)\n    \n    # Find the best parameters\n    best_parameters = dict(zip(parameters.keys(), params[np.argmax(list(results.values()))]))\n    best_accuracy = np.max(list(results.values()))\n    best = (best_parameters, best_accuracy)\n\n    # Add the param name to the results\n    results = [({k: v for k, v in zip(parameters.keys(), p)}, a) for p, a in results.items()]\n\n    return best, results",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## A) Hyper-parameter search\n\n### TO DO (A.0)\n\n**Set** the random **seed** using your **ID**. If you need to change it for testing add a constant explicitly, eg.: 1234567 + 1",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# fix your ID (\"numero di matricola\") and the seed for random generator\n# as usual you can try different seeds by adding a constant to the number:\n# ID = 1234567 + X\nID = 2122166 # YOUR ID (replace None with your ID)\nnp.random.seed(ID)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Before proceding to the training steps, we **load the dataset and split it** in training and test set (while the **training** set is **typically larger**, here we set the number of training samples to 1000 and 4000 for the test data).\nThe **split** is **performed after applying a random permutation** to the dataset, such permutation will **depend on the seed** you set above.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Load the dataset using the helper function\nX, y = load_dataset(\"data/lux.npz\")\nprint(X.shape, y.shape)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# The task is quite easy, let's add noise to make it more challenging!\n# You can try without noise (comment the next 2 lines, easy task), with the suggested amount of noise,\n# or play with the suggested amount of noise \n\nnoise = np.random.normal(0, 0.1, X.shape)\nX = X + noise",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (A.1)\n\n**Divide** the **data into training and test set** (for this part use 1000 samples in the **first** set, 4000 in the **second** one). Make sure that each label is present at least 10 times in training. If it is not, then keep adding permutations to the initial data until this happens.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Random permute the data and split into training and test taking the first 1000\n# data samples as training and 4000 samples as test\npermutation = np.random.shuffle(np.arange(X.shape[0])) # ADD YOUR CODE HERE (replace None)\n\nX = X[permutation] # ADD YOUR CODE HERE (replace None)\ny = y[permutation] # ADD YOUR CODE HERE (replace None)\n\nm_training = 1000\nm_test = 4000\n\nX_train = X[:m_training] # ADD YOUR CODE HERE (replace None)\nX_test = X[m_training:m_training+m_test] # ADD YOUR CODE HERE (replace None)\ny_train = y[:m_training] # ADD YOUR CODE HERE (replace None)\ny_test = y[m_training:m_training+m_test] # ADD YOUR CODE HERE (replace None)\n\nprint(\"X_train shape:\", X_train.shape,\"X_test shape:\", X_test.shape,\"||\",\"y_train shape:\",  y_train.shape,\"y_test shape:\", y_test.shape)\n\nlabels, freqs = None # ADD YOUR CODE HERE. Hint: use np.unique() (replace None)\nprint(\"Labels in training dataset: \", labels)\nprint(\"Frequencies in training dataset: \", freqs)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Let's try the plotting function\nplot_input(X_train,y_train)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (A.2)\n\nUse a SVM classfier with cross validation to pick a model. Use a 4-fold cross-validation. Let's start with a Linear kernel.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Parameters for linear SVM\nparameters = {'C': [ 0.01, 0.1, 1, 10]}\n\n# Define the model (without parameters)\nsvm = SVC(kernel='poly', degree=1) # ADD YOUR CODE HERE (replace None)\n\n# Perform the K-fold cross validation\nk = 4 # nc\nbest, results = k_fold_cross_validation(X_train, y_train, k, svm, parameters) # ADD YOUR CODE HERE (replace None)\n\nprint ('RESULTS FOR LINEAR KERNEL')\n\nprint(\"Best parameter set found:\")\n# ADD YOUR CODE HERE\nprint(best[0]) # nc\n\nprint(\"Score with best parameter:\")\n# ADD YOUR CODE HERE\nprint(best[1]) # nc\nprint()\nprint(\"All scores on the grid:\")\n# ADD YOUR CODE HERE\nprint(results) # nc",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (A.3)\n\nPick a model for the Polynomial kernel with degree=2.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Parameters for linear SVM\nparameters = {'C': [0.01, 0.1, 1],'gamma':[0.01,0.1,1.]}\n\n# Define an SVM with poly of degree 2 kernel (without parameters)\npoly2_svm = SVC(kernel='poly', degree=2) # ADD YOUR CODE HERE (replace None)\n\n# Perform the K-fold cross validation\nbest, results = k_fold_cross_validation(X_train, y_train, k, poly2_svm, parameters) # ADD YOUR CODE HERE (replace None)\n\nprint ('RESULTS FOR POLY DEGREE=2 KERNEL')\n\nprint(\"Best parameter set found:\")\n# ADD YOUR CODE HERE\nprint(best[0]) # nc\n\nprint(\"Score with best parameter:\")\n# ADD YOUR CODE HERE\nprint(best[1]) # nc\nprint()\nprint(\"All scores on the grid:\")\n# ADD YOUR CODE HERE\nprint(results) # nc",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (A.4)\n\nNow let's try a higher degree for the polynomial kernel (e.g., 3rd degree).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Parameters for poly with higher degree kernel\nparameters = {'C': [0.01, 0.1, 1],'gamma':[0.01,0.1, 1]}\n\n# Define an SVM with poly of higher degree kernel (without parameters)\ndegree = 3\npoly_svm = SVC(kernel='poly', degree=degree) # ADD YOUR CODE HERE (replace None)\n\n# Perform the K-fold cross validation\nbest, results = k_fold_cross_validation(X_train, y_train, k, poly_svm, parameters) # ADD YOUR CODE HERE (replace None)\n\nprint (f\"RESULTS FOR POLY DEGREE={degree} KERNEL\")\n\nprint(\"Best parameter set found:\")\n# ADD YOUR CODE HERE\nprint(best[0]) # nc\n\nprint(\"Score with best parameter:\")\n# ADD YOUR CODE HERE\nprint(best[1]) # nc\nprint()\nprint(\"All scores on the grid:\")\n# ADD YOUR CODE HERE\nprint(results) # nc",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (A.5)\n\nPick a model for the Radial Basis Function kernel:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Parameters for rbf SVM\nparameters = {'C': [0.1, 1, 10, 100],'gamma':[0.001, 0.01, 0.1,1]}\n\n# Define an SVM with rbf kernel (without parameters)\nrbf_svm = SVC(kernel='rbf') # ADD YOUR CODE HERE (replace None)\n\n# Perform the K-fold cross validation\nbest, results = k_fold_cross_validation(X_train, y_train, k, rbf_svm, parameters) # ADD YOUR CODE HERE (replace None)\n\nprint ('RESULTS FOR rbf KERNEL')\n\nprint(\"Best parameter set found:\")\n# ADD YOUR CODE HERE\nprint(best[0]) # nc\n\nprint(\"Score with best parameter:\")\n# ADD YOUR CODE HERE\nprint(best[1]) # nc\nprint()\nprint(\"All scores on the grid:\")\n# ADD YOUR CODE HERE\nprint(results) # nc",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (A.Q1) [Answer the following]\n\nWhat do you observe when using RBF and polynomial kernels on this dataset ?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**ANSWER A.Q1:**: Answer here",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (A.6)\nReport here the best SVM kernel and parameters",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Get training and test error for the best SVM model from CV\nbest_svm = SVC(kernel='rbf', parameters=) # USE YOUR OPTIMAL PARAMETERS HERE (replace None)\n\n# Run the svm model on the whole training set\nbest_svm.fit(X_train, y_train)\n\n# Compute the errors\n# (error is 1 - svm.score)\ntraining_error = 1 - best_svm.score(X_train, y_train) # ADD YOUR CODE (replace None)\ntest_error = 1 - best_svm.score(X_test, y_test) # ADD YOUR CODE (replace None)\n\nprint (\"Best SVM training error: %f\" % training_error)\nprint (\"Best SVM test error: %f\" % test_error)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (A.7)\n\nAnalyze how the gamma parameter (inversely proportional to standard deviation of Gaussian Kernel) impact the performances of the classifier",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Test with different values of gamma\n# use rbf kernel and C=1\n\n# Set gamma values\ngamma_values = np.logspace(-5,2,8)\nprint(gamma_values)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "train_acc_list, test_acc_list = [], []\n\n# ADD YOUR CODE TO TRAIN THE SVM MULTIPLE TIMES WITH THE DIFFERENT VALUES OF GAMMA\n# PLACE THE TRAIN AND TEST ACCURACY FOR EACH TEST IN THE TRAIN AND TEST ACCURACY LISTS",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Plot\nfig, ax = plt.subplots(1,2, figsize=(15,5))\n\nax[0].plot(gamma_values, train_acc_list)\nax[0].set_xscale('log')\nax[0].set_xlabel('gamma')\nax[0].set_ylabel('Train accuracy')\nax[0].grid(True)\n\nax[1].plot(gamma_values, test_acc_list)\nax[1].set_xscale('log')\nax[1].set_xlabel('gamma')\nax[1].set_ylabel('Test accuracy')\nax[1].grid(True)\n\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## B) More data\nNow let's do the same but using more data points for training.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (B.0)\n\nChoose a higher number of data points (e.g. x = 10000) for training data depending on your computing capability.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = X[permutation]\ny = y[permutation]\n\nm_training = 10000 # ADD YOUR CODE: adjust depending on the capabilities of your PC (replace None)\n\nX_train, X_test = X[:m_training], X[m_training:]\ny_train, y_test = y[:m_training], y[m_training:]\n\nlabels, freqs = None # ADD YOUR CODE (replace None)\nprint(\"Labels in training dataset: \", labels)\nprint(\"Frequencies in training dataset: \", freqs)\n\n# initialize support variables for boundaries visualization\ngranularity = 25\nx_max = np.abs(X).max()\nx_range = np.linspace(-x_max, x_max, granularity)\nx_grid = np.stack(np.meshgrid(x_range, x_range, x_range)).reshape(3, -1).T",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (B.1)\n\nLet's try to use SVM with parameters obtained from the best model for $m_{training} =  10000$. Since it may take a long time to run, you can decide to just let it run for some time and stop it if it does not complete. If you decide to do this, report it in the TO DO (C.Q1) cell below.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Get training and test error for the best SVM model from CV\n\n# ADD YOUR CODE\nbest_svm.fit(X_train, y_train) # nc\ntraining_error = 1 - best_svm.score(X_train, y_train) # nc\ntest_error = 1 - best_svm.score(X_test, y_test) # nc\n\nprint (\"Best SVM training error: %f\" % training_error)\nprint (\"Best SVM test error: %f\" % test_error)",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## C) Boundaries Visualization\n\nNow let us plot the classification boundaries. ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (C.0)\n\nUse the SVM to predict on the test set X_test. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "rbf_svm_test = rbf_svm.predict(X_test) # ADD YOUR CODE (replace None)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We constructed a grid of all possible combinations of input values, we now use it to extract the classification boundaries of the three classifiers by having them predict on each input.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "rbf_SVM_grid = rbf_svm.predict(x_grid)\n\nrbf_SVM_m = y_test == rbf_svm_test\n\nfig = plt.figure()\nax1 = fig.add_subplot(1, 1, 1, projection=\"3d\")\n\nax1.scatter(x_grid[:,0], x_grid[:,1], x_grid[:,2], c=rbf_SVM_grid, linewidth=0, marker=\"s\", alpha=.05,cmap='Accent')\n\nax1.scatter(X_test[rbf_SVM_m,0], X_test[rbf_SVM_m,1], X_test[rbf_SVM_m,2], c=y_test[rbf_SVM_m], linewidth=.5, edgecolor=\"k\", marker=\".\",cmap='Accent')\nax1.scatter(X_test[~rbf_SVM_m,0], X_test[~rbf_SVM_m,1], X_test[~rbf_SVM_m,2], c=y_test[~rbf_SVM_m], linewidth=1, edgecolor=\"r\", marker=\".\",cmap='Accent')\nax1.set_xlim([-x_max, x_max])\nax1.set_ylim([-x_max, x_max])\nax1.set_zlim([-x_max, x_max])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (C.Q1) [Answer the following]**\n\nCompare and discuss the results from SVM with m=600 and with m=10000 (or whatever value you set) training data points. If you stopped the SVM, include such aspect in your comparison.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**ANSWER C.Q1:** Answer here",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (C.1)\n\nPlot the confusion matrix for the SVM classifier. The confusion matrix has one column for each predicted label and one row for each true label. \nIt shows for each class in the corresponding row how many samples belonging to that class gets each possible output label. Notice that the diagonal contains the correctly classified samples, while the other cells correspond to errors. You can obtain it with the sklearn.metrics.confusion_matrix function (see the documentation). You can also print also the normalized confusion matrix.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "np.set_printoptions(precision=2, suppress=True) # for better aligned printing of confusion matrix use floatmode='fixed'\n\nu, counts = np.unique(y_test, return_counts=True)\nprint(\"Labels and frequencies in test set: \", counts)\n\nconfusion_SVM = sk.confusion_matrix(y_test, rbf_svm_test) # ADD YOUR CODE\nprint(\"\\n Confusion matrix SVM  \\n \\n\", confusion_SVM)\nprint(\"\\n Confusion matrix SVM (normalized)   \\n \\n\", confusion_SVM /counts[:,None] )",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure()\n    \nim = plt.imshow(confusion_SVM /counts[:,None], cmap=\"Blues\",interpolation='nearest')\nplt.xticks([0,1,2,3], ['Sunny', 'Rainy','Cloudy', 'Mostly clear'],ha=\"right\",rotation=30)\nplt.yticks([0,1,2,3], ['Sunny', 'Rainy','Cloudy', 'Mostly clear'],ha=\"right\",rotation=30)\ncm = confusion_SVM /counts[:,None]\nfmt = '.2f'\nthresh = cm.max() / 2.\nfor i in range(cm.shape[0]):\n    for j in range(cm.shape[1]):\n        plt.text(j, i, format(cm[i, j], fmt),\n        ha=\"center\", va=\"center\",\n        color=\"white\" if cm[i, j] > thresh else \"black\")\n\nfig.tight_layout()\nfig.colorbar(im, location='bottom')  \nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### TO DO (C.Q2) [Answer the following]\n\nHave a look at the confusion matrix and comment on the obtained accuracies. Why some classes have lower accuracies and others an higher one? Make some guesses on the possible causes.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**ANSWER C.Q2:** Answer here",
      "metadata": {}
    }
  ]
}